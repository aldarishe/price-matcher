import streamlit as st
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import io

st.set_page_config(page_title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω (–ë—Ä–µ–Ω–¥-–∫–æ–Ω—Ç—Ä–æ–ª—å)", page_icon="üõ°Ô∏è", layout="wide")

st.title("üõ°Ô∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω (—Å —É—á–µ—Ç–æ–º –ë—Ä–µ–Ω–¥–æ–≤)")
st.markdown("""
–≠—Ç–æ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º —Å—Ç—Ä–æ–∂–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Å–ª–æ–≤. 
–ï—Å–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö **—Ä–∞–∑–Ω—ã–µ –±—Ä–µ–Ω–¥—ã** (–Ω–∞–ø—Ä–∏–º–µ—Ä, –£–≤–µ–ª–∫–∞ –∏ –ü–∞—Å—Å–∏–º), —Å—Ö–æ–¥—Å—Ç–≤–æ –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ —Å–Ω–∏–∂–µ–Ω–æ.
""")

def aggressive_clean_name(name):
    if not isinstance(name, str):
        return ""
    name = name.lower().replace('—ë', '–µ')
    name = re.sub(r'(?<=\d)(?=[–∞-—èa-z])', ' ', name)
    name = re.sub(r'(?<=[–∞-—èa-z])(?=\d)', ' ', name)
    name = name.replace(',', '.')
    return re.sub(r'[^a-z–∞-—è0-9\s\.]', ' ', name).strip()

def get_tokens(text):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å–ª–æ–≤ (set)"""
    return set(text.split())

def calculate_similarity_with_penalty(df1, df2, name_col1, name_col2):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ, –Ω–æ —à—Ç—Ä–∞—Ñ—É–µ—Ç, –µ—Å–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö –µ—Å—Ç—å —Ä–∞–∑–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞.
    """
    # 1. –ë–∞–∑–æ–≤—ã–π TF-IDF (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))
    
    corpus = df1['clean_name'].tolist() + df2['clean_name'].tolist()
    vectorizer.fit(corpus)
    
    tfidf1 = vectorizer.transform(df1['clean_name'])
    tfidf2 = vectorizer.transform(df2['clean_name'])
    
    cosine_sim = cosine_similarity(tfidf1, tfidf2)
    
    # 2. –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ (–ë—Ä–µ–Ω–¥-–∫–æ–Ω—Ç—Ä–æ–ª—å)
    # –ï—Å–ª–∏ —Å–ª–æ–≤–∞ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è, –º—ã —É–º–µ–Ω—å—à–∞–µ–º score
    
    matches = []
    
    # –ß—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–æ–±—å–µ–º –≤—Å–µ –Ω–∞ —Å–ª–æ–≤–∞
    tokens1 = [get_tokens(n) for n in df1['clean_name']]
    tokens2 = [get_tokens(n) for n in df2['clean_name']]
    
    total_items = len(df1)
    progress_bar = st.progress(0)

    for i in range(total_items):
        if i % (total_items // 10 + 1) == 0:
            progress_bar.progress(i / total_items)

        # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ TF-IDF, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–±–∏—Ä–∞—Ç—å –≤—Å–µ—Ö
        # (—ç—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É)
        best_candidates_indices = cosine_sim[i].argsort()[-5:][::-1]
        
        best_score = 0
        best_match_idx = -1
        
        for idx in best_candidates_indices:
            raw_score = cosine_sim[i][idx]
            
            # –õ–æ–≥–∏–∫–∞ —à—Ç—Ä–∞—Ñ–∞:
            # –ù–∞—Ö–æ–¥–∏–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –æ–¥–Ω–æ–º –Ω–∞–∑–≤–∞–Ω–∏–∏, –Ω–æ –Ω–µ—Ç –≤ –¥—Ä—É–≥–æ–º
            t1 = tokens1[i]
            t2 = tokens2[idx]
            
            # –°–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å (—Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–≤–ø–∞–ª–∏)
            diff = t1.symmetric_difference(t2)
            
            # –ï—Å–ª–∏ "—Ä–∞–∑–Ω—ã—Ö" —Å–ª–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–ª–∏–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏—è, —à—Ç—Ä–∞—Ñ—É–µ–º
            # –£–≤–µ–ª–∫–∞ vs –ü–∞—Å—Å–∏–º -> diff = {'—É–≤–µ–ª–∫–∞', '–ø–∞—Å—Å–∏–º'} (2 —Å–ª–æ–≤–∞)
            penalty = 0.0
            
            if len(diff) > 0:
                # –®—Ç—Ä–∞—Ñ—É–µ–º –Ω–∞ 15% –∑–∞ –∫–∞–∂–¥–æ–µ –Ω–µ—Å–æ–≤–ø–∞–¥–∞—é—â–µ–µ —Å–ª–æ–≤–æ
                # –ù–æ –Ω–µ –±–æ–ª—å—à–µ 50%
                penalty = min(len(diff) * 0.15, 0.5)
            
            final_score = raw_score - penalty
            
            if final_score > best_score:
                best_score = final_score
                best_match_idx = idx
        
        matches.append((best_match_idx, best_score))
            
    progress_bar.progress(100)
    return matches

def find_best_column(df, target_type):
    cols = df.columns
    cols_lower = [str(c).lower() for c in cols]
    if target_type == 'name':
        keywords = ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'name', '—Ç–æ–≤–∞—Ä', 'product']
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–¥—ã
        for k in keywords:
            for i, col_name in enumerate(cols_lower):
                if k in col_name and not any(x in col_name for x in ['–∫–æ–¥', 'id', 'sku']):
                    return cols[i]
    elif target_type == 'price':
        keywords = ['—Ü–µ–Ω–∞', 'price', 'rub']
        for k in keywords:
            for i, col_name in enumerate(cols_lower):
                if k in col_name:
                    return cols[i]
    return None

def process_files(file1, file2, threshold):
    df1 = pd.read_excel(file1)
    df2 = pd.read_excel(file2)
    
    name_col1 = find_best_column(df1, 'name')
    price_col1 = find_best_column(df1, 'price')
    name_col2 = find_best_column(df2, 'name')
    price_col2 = find_best_column(df2, 'price')

    if not all([name_col1, price_col1, name_col2, price_col2]):
        st.error("–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–ª–æ–Ω–æ–∫")
        return None

    df1['clean_name'] = df1[name_col1].apply(aggressive_clean_name)
    df2['clean_name'] = df2[name_col2].apply(aggressive_clean_name)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —É–º–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    results = calculate_similarity_with_penalty(df1, df2, name_col1, name_col2)
    
    final_matches = []
    for i, (best_idx, score) in enumerate(results):
        if score > threshold:
            final_matches.append({
                '–¢–æ–≤–∞—Ä (–ù–∞—à)': df1.iloc[i][name_col1],
                '–¢–æ–≤–∞—Ä (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)': df2.iloc[best_idx][name_col2],
                '–°—Ö–æ–¥—Å—Ç–≤–æ (%)': round(score * 100, 1),
                '–¶–µ–Ω–∞ (–ù–∞—à–∞)': df1.iloc[i][price_col1],
                '–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)': df2.iloc[best_idx][price_col2]
            })
            
    if not final_matches:
        return None
        
    res_df = pd.DataFrame(final_matches)
    res_df['–†–∞–∑–Ω–∏—Ü–∞'] = res_df['–¶–µ–Ω–∞ (–ù–∞—à–∞)'] - res_df['–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)']
    cols_order = ['–¢–æ–≤–∞—Ä (–ù–∞—à)', '–¢–æ–≤–∞—Ä (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)', '–¶–µ–Ω–∞ (–ù–∞—à–∞)', '–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)', '–†–∞–∑–Ω–∏—Ü–∞', '–°—Ö–æ–¥—Å—Ç–≤–æ (%)']
    return res_df[cols_order]

# --- UI ---
col1, col2 = st.columns(2)
with col1:
    file1 = st.file_uploader("–§–∞–π–ª 1", type=['xlsx', 'xls'], key="f1")
with col2:
    file2 = st.file_uploader("–§–∞–π–ª 2", type=['xlsx', 'xls'], key="f2")

threshold_val = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞", 0.0, 1.0, 0.60, 0.05)

if file1 and file2:
    if st.button("üöÄ –°—Ä–∞–≤–Ω–∏—Ç—å", type="primary"):
        res = process_files(file1, file2, threshold_val)
        if res is not None and not res.empty:
            st.success(f"–ù–∞–π–¥–µ–Ω–æ: {len(res)}")
            st.dataframe(res, use_container_width=True)
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                res.to_excel(writer, index=False)
            st.download_button("–°–∫–∞—á–∞—Ç—å Excel", buffer.getvalue(), "result.xlsx")
        else:
            st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
