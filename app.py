import streamlit as st
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import io

st.set_page_config(page_title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω (Simple)", page_icon="‚öñÔ∏è", layout="wide")

st.title("‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω (–¢–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã)")
st.markdown("""
–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–≤–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞. –°–∫—Ä–∏–ø—Ç –Ω–∞–π–¥–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –∏ —Å—Ä–∞–≤–Ω–∏—Ç —Ü–µ–Ω—ã.
–ö–æ–¥—ã —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É –Ω–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è.
""")

def clean_name(name):
    if not isinstance(name, str):
        return ""
    name = name.lower()
    return re.sub(r'[\s\W_]+', ' ', name).strip()

def find_best_column(df, target_type):
    """
    –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫.
    –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–¥–∞–º–∏ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω–∞–∑–≤–∞–Ω–∏–π, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è.
    """
    cols = df.columns
    cols_lower = [c.lower() for c in cols]
    
    if target_type == 'name':
        # 1. –ò—â–µ–º —è–≤–Ω–æ–µ "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ" –∏–ª–∏ "–Ω–∞–∑–≤–∞–Ω–∏–µ"
        strict_keywords = ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'name']
        for k in strict_keywords:
            for i, col_name in enumerate(cols_lower):
                if k in col_name:
                    return cols[i]
        
        # 2. –ò—â–µ–º "—Ç–æ–≤–∞—Ä", –ù–û —Å—Ç—Ä–æ–≥–æ –∏—Å–∫–ª—é—á–∞–µ–º "–∫–æ–¥", "id", "sku"
        # –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É, –∫–æ–≥–¥–∞ "–ö–æ–¥ —Ç–æ–≤–∞—Ä–∞" —Å—á–∏—Ç–∞–ª—Å—è –Ω–∞–∑–≤–∞–Ω–∏–µ–º
        soft_keywords = ['—Ç–æ–≤–∞—Ä', '–ø—Ä–æ–¥—É–∫—Ç', 'product', 'item']
        for k in soft_keywords:
            for i, col_name in enumerate(cols_lower):
                if k in col_name and not any(x in col_name for x in ['–∫–æ–¥', 'id', 'sku', 'code']):
                    return cols[i]

    elif target_type == 'price':
        keywords = ['—Ü–µ–Ω–∞', 'price', 'cost', '—Å—É–º–º–∞', 'rub', '—Ä—É–±']
        for k in keywords:
            for i, col_name in enumerate(cols_lower):
                if k in col_name:
                    return cols[i]
    return None

def process_files(file1, file2, threshold):
    df1 = pd.read_excel(file1)
    df2 = pd.read_excel(file2)
    
    # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –ù–∞–∑–≤–∞–Ω–∏–µ –∏ –¶–µ–Ω—É
    name_col1 = find_best_column(df1, 'name')
    price_col1 = find_best_column(df1, 'price')
    
    name_col2 = find_best_column(df2, 'name')
    price_col2 = find_best_column(df2, 'price')

    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.info(f"""
    **–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
    –§–∞–π–ª 1: –¢–æ–≤–∞—Ä='{name_col1}', –¶–µ–Ω–∞='{price_col1}'
    –§–∞–π–ª 2: –¢–æ–≤–∞—Ä='{name_col2}', –¶–µ–Ω–∞='{price_col2}'
    """)

    if not name_col1 or not price_col1 or not name_col2 or not price_col2:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∏–ª–∏ —Ü–µ–Ω–æ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤.")
        return None

    df1['clean_name'] = df1[name_col1].apply(clean_name)
    df2['clean_name'] = df2[name_col2].apply(clean_name)
    
    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))
    tfidf_matrix1 = vectorizer.fit_transform(df1['clean_name'].astype(str))
    tfidf_matrix2 = vectorizer.transform(df2['clean_name'].astype(str))
    
    cosine_sim = cosine_similarity(tfidf_matrix1, tfidf_matrix2)
    
    matches = []
    
    progress_bar = st.progress(0)
    total_items = len(df1)
    
    for i in range(total_items):
        if i % (total_items // 10 + 1) == 0:
            progress_bar.progress(i / total_items)
            
        best_idx = cosine_sim[i].argmax()
        score = cosine_sim[i][best_idx]
        
        if score > threshold:
            matches.append({
                '–¢–æ–≤–∞—Ä (–ù–∞—à)': df1.iloc[i][name_col1],
                '–¢–æ–≤–∞—Ä (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)': df2.iloc[best_idx][name_col2],
                '–°—Ö–æ–¥—Å—Ç–≤–æ (%)': round(score * 100, 1),
                '–¶–µ–Ω–∞ (–ù–∞—à–∞)': df1.iloc[i][price_col1],
                '–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)': df2.iloc[best_idx][price_col2]
            })
            
    progress_bar.progress(100)
    
    if not matches:
        return None
        
    res_df = pd.DataFrame(matches)
    res_df['–†–∞–∑–Ω–∏—Ü–∞'] = res_df['–¶–µ–Ω–∞ (–ù–∞—à–∞)'] - res_df['–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)']
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (–±–µ–∑ –∫–æ–¥–æ–≤)
    cols_order = ['–¢–æ–≤–∞—Ä (–ù–∞—à)', '–¢–æ–≤–∞—Ä (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)', '–¶–µ–Ω–∞ (–ù–∞—à–∞)', '–¶–µ–Ω–∞ (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)', '–†–∞–∑–Ω–∏—Ü–∞', '–°—Ö–æ–¥—Å—Ç–≤–æ (%)']
    return res_df[cols_order]

# --- UI ---

col1, col2 = st.columns(2)
with col1:
    file1 = st.file_uploader("–§–∞–π–ª 1 (–û—Å–Ω–æ–≤–Ω–æ–π)", type=['xlsx', 'xls'], key="f1")
with col2:
    file2 = st.file_uploader("–§–∞–π–ª 2 (–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç)", type=['xlsx', 'xls'], key="f2")

threshold_val = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞", 0.0, 1.0, 0.65, 0.05)

if file1 and file2:
    if st.button("üöÄ –°—Ä–∞–≤–Ω–∏—Ç—å", type="primary"):
        try:
            res = process_files(file1, file2, threshold_val)
            if res is not None and not res.empty:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(res)}")
                st.dataframe(res, use_container_width=True)
                
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    res.to_excel(writer, index=False)
                
                st.download_button("–°–∫–∞—á–∞—Ç—å Excel", buffer.getvalue(), "result.xlsx")
            else:
                st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
